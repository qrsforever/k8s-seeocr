kind: Service
apiVersion: v1
metadata:
  name: seeocr-rec-service
  namespace: seeocr
spec:
  selector:
    app: seeocr-rec-app
  ports:
    - port: 21616
      targetPort: 2828

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: seeocr-rec-deployment
  namespace: seeocr
  labels:
    app: seeocr-rec-app
spec:
  selector:
    matchLabels:
      app: seeocr-rec-app
  replicas: 1
  template:
    metadata:
      labels:
        app: seeocr-rec-app
    spec:
      containers:
        - name: seeocr-rec
          image: hzcsk8s.io/seeocr_paddle_gpu
          imagePullPolicy: Always
          ports:
            - containerPort: 2828
          command: ["/bin/bash"]
          args: ["-c", "python3 app_service.py --task seeocr.rec"]

          env:
            - name: KAFKA_HOST
              valueFrom:
                configMapKeyRef:
                  name: seeocr-kafka-cm
                  key: kafka_host

            - name: KAFKA_PORT
              valueFrom:
                configMapKeyRef:
                  name: seeocr-kafka-cm
                  key: kafka_port

          resources:
            limits:
              nvidia.com/gpu: 1

          livenessProbe:
            exec:
              command: ["test", "-e", "/tmp/healthy"]
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 30
            failureThreshold: 3

          volumeMounts:
            - name: k8s-nfs
              mountPath: /data
              subPath: seeocr

      volumes:
      - name: k8s-nfs
        persistentVolumeClaim:
          claimName: seeocr-pvc-nfs

      restartPolicy: Always
      terminationGracePeriodSeconds: 10

      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

      # nodeSelector:
      #   accelerator: "nvidia-tesla-t4"
